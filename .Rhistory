source('~/r_projects/linked_data_survey/survey_analysis.R')
source('~/r_projects/linked_data_survey/survey_analysis.R')
get_sentiments("nrc")
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("nrc"))
tokenized_survey$sentiment <- NULL
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("nrc"))
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("afinn"))
source('~/r_projects/linked_data_survey/survey_analysis.R')
get_sentiments('loughran')
###################
## Automate package install and load
is_installed <- function(package_name) is.element(package_name, installed.packages()[,1])
# If a package is not installed, install it. Then load the package.
install_and_load <- function(package_name) {
if(!is_installed(package_name)) {
install.packages(package_name)
}
library(package_name, character.only = TRUE)
}
install_packages <- function(packages) {
for(package in packages) {
install_and_load(package)
}
}
# Install and load libraries
install_packages(c("dplyr", "tidytext", "readr", "ggplot2", "stringr"))
survey = read_csv('ld_results_final__for_rob_recoded_trimmed.csv', col_names = TRUE)
survey$combined_words <- paste(survey$linked_data_description, survey$linked_data_benefits, survey$additional_thoughts)
tokenized_survey <- survey %>% unnest_tokens(word, combined_words)
data("stop_words")
tokenized_survey <- tokenized_survey %>% anti_join(stop_words)
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("bing"))
tokenized_survey$bing_sentiment <- tokenized_survey$sentiment
tokenized_survey$sentiment <- NULL
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("nrc"))
tokenized_survey$nrc_sentiment <- tokenized_survey$sentiment
source('~/r_projects/linked_data_survey/survey_analysis.R')
View(tokenized_survey_nrc)
View(tokenized_survey_nrc)
View(tokenized_survey_nrc)
<<<<<<< HEAD
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
=======
temp <- count(tokenized_survey$word, tokenized_survey$bing_sentiment, sort = TRUE)
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE)
source('~/r_projects/linked_data_survey/survey_analysis.R')
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE)
bing_word_counts <- tokenized_survey %>% count(word, bing_sentiment, sort = TRUE)
help("group_by")
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
tokenized_survey <- survey %>% unnest_tokens(word, combined_words)
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10)
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup()
help("ungroup")
help("mutate")
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n))
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill=bing_sentiment)) + geom_col(show.legend = FALSE)
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill=bing_sentiment)) + geom_col(show.legend = FALSE)
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill=bing_sentiment)) + geom_col(show.legend = FALSE)
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill=bing_sentiment)) + geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = 'free_y')
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill=bing_sentiment)) + geom_col(show.legend = FALSE) +
facet_wrap(~sentiment)
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill=bing_sentiment)) + geom_col(show.legend = FALSE) +
facet_wrap(~bing_sentiment)
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill=bing_sentiment)) + geom_col(show.legend = FALSE) +
facet_wrap(~bing_sentiment) +
coord_flip()
tokenized_survey %>% count(word, bing_sentiment, sort = TRUE) %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill=bing_sentiment)) + geom_col(show.legend = FALSE) +
facet_wrap(~bing_sentiment, scales = "free_y") +
coord_flip()
bing_word_counts <- tokenized_survey %>%
count(word, bing_sentiment, sort = TRUE) %>%
ungroup()
View(bing_word_counts)
View(bing_word_counts)
bing_word_counts %>%
group_by(binb_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
bing_word_counts %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
bing_word_counts %>%
group_by(bing_sentiment) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = bing_sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~bing_sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
>>>>>>> d3dc5fd8858de679c707f7bdb0942ea2fb143422
bing_word_counts %>%
group_by(bing_sentiment) %>%
top_n(7) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = bing_sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~bing_sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
<<<<<<< HEAD
View(tokenized_survey)
View(tokenized_survey)
View(tokenized_survey_nrc)
View(tokenized_survey_nrc)
View(tokenized_survey)
View(tokenized_survey)
View(survey)
View(survey)
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
library("topicmodels", lib.loc="~/Library/R/3.3/library")
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
install_url(slam_url)
R.version()
R.Version()
=======
View(survey)
View(survey)
install_packages(c("dplyr", "tidytext", "readr", "ggplot2", "stringr", "dataMeta"))
source('~/r_projects/linked_data_survey/survey_analysis.R')
source('~/r_projects/linked_data_survey/survey_analysis.R')
names(survey)
column_descriptions <- c("Date the survey was started",
"Date the survey was completed",
"Where the survey was filled out [IP Address = web]",
"Percentage of the survey completed",
"The time taken to complete the survey in seconds",
"If the survey was completed",
"Date the survey was completed",
"Unique anonymous identifier for the response",
"Respondants area of work,")
column_types <- c(0, 0, 1, 0, 0, 1, 0, 0, 1)
install_packages(c("dplyr", "tidytext", "readr", "ggplot2", "stringr", "dataMeta"))
linker <- build_linker(survey, column_descriptions, column_types)
column_types <- c(0, 0, 0,
0, 0, 1,
0, 0, 1,
0, 1, 0,
0, 0, 0,
0, 0, 0,
0)
column_descriptions <- c("Date the survey was started",
"Date the survey was completed",
"Where the survey was filled out [IP Address = web]",
"Percentage of the survey completed",
"The time taken to complete the survey in seconds",
"If the survey was completed",
"Date the survey was completed",
"Unique anonymous identifier for the response",
"Respondants area of work",
"Explanation of other response in work area",
"Recoded work area to group like explanations",
"Respondants description of what linked data is to a non expert",
"Quality of the descriptiong scored independently by the authors",
"If the respondant was postive, negative or neutral towards linked data, estimated by the authors",
"Respondants description of the benefits of linked data",
"The quality of the benefits answer, scored indepenently by the authors",
"If the respondants felt linked data was beneficial, not beneficial or neutral",
"Respondants can add additional comments",
"The three text responsed, linked_data_description, linked_data_benefits and additional_thoughts combined"
)
linker <- build_linker(survey, column_descriptions, column_types)
View(linker)
dict ,_ build_dict(my.data = survey, linker = linker, option_description = NULL, prompt_varopts = FALSE)
dict <- build_dict(my.data = survey, linker = linker, option_description = NULL, prompt_varopts = FALSE)
dict <- build_dict(my.data = survey, linker = linker, option_description = NULL, prompt_varopts = FALSE)
dict <- build_dict(survey = survey, linker = linker, option_description = NULL, prompt_varopts = FALSE)
dict <- build_dict(my.data = survey, linker = linker, option_description = NULL, prompt_varopts = FALSE)
dict <- build_dict(my.data = survey, linker = linker, option_description = NULL, prompt_varopts = FALSE)
source('~/r_projects/linked_data_survey/survey_analysis.R')
dict <- build_dict(my.data = survey, linker = linker, option_description = NULL, prompt_varopts = FALSE)
edit(survey)
edit(survey)
edit(survey)
View(survey)
View(survey)
source('~/r_projects/linked_data_survey/survey_analysis.R')
dict <- build_dict(my.data = survey, linker = linker, option_description = NULL, prompt_varopts = FALSE)
linker <- build_linker(survey, variable_description = column_descriptions, variable_type = column_types)
dict <- build_dict(my.data = survey, linker = linker, op)
dict <- build_dict(my.data = survey, linker = linker, option_description = NULL, prompt_varopts = FALSE)
path = "http://raw.githubusercontent.com/cdcepi/zika/master/"
path2 = "USVI/USVI_Zika/data/USVI_Zika-2017-01-03.csv"
url <- paste0(path, path2, collapse="")
my.data <- read.csv(url, header = TRUE, stringsAsFactors = FALSE)
var_desc <- c("Date when report was published", "Regional location",
"Description of regional location", "Type of case",
"A specific code for each data field", "The time period of each week",
"The type of time period", "The number of cases per data field type",
"The unit in which cases are reported")
var_type <- c(0, 1, 0, 1, 0, 0, 0, 0, 1)
linker <- build_linker(my.data, variable_description = var_desc, variable_type = var_type)
dict <- build_dict(my.data = my.data, linker = linker, option_description = NULL,
prompt_varopts = FALSE)
kable(dict, format = "html", caption = "Data dictionary for original dataset")
View(dict)
install.packages("topicmodels")
source('~/r_projects/linked_data_survey/survey_analysis.R')
library("topicmodels", lib.loc="~/R/win-library/3.3")
install.packages("topicmodels")
install.packages("slam")
library("installr", lib.loc="~/R/win-library/3.3")
updateR()
>>>>>>> d3dc5fd8858de679c707f7bdb0942ea2fb143422
