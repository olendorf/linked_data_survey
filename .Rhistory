R.Version()
library(dplyr)
install.packages("dplyr")
library(ggplot2)
install.packages("ggplot2")
library(lubridate)
install.packages("lubridate")
library(knitr)
bulkspeed <- read.delim("./data/bulkspeed201412.txt", stringsAsFactors=FALSE)
bulkspeed <- bulkspeed[ -c(2,4,6,8,10,12,14,16,18,20,22,24) ]
Durationsecs <- sapply(bulkspeed$Duration, function(x) parseduration(x))
df <- as.data.frame(Durationsecs)
bulkspeed <- cbind(bulkspeed, df)
bulkspeed <- mutate(bulkspeed, Secs.Bib = round(Durationsecs / Records, 2))
bulkspeed <- mutate(bulkspeed, Datetime = mdy_hm(bulkspeed$Start))
bulkspeed <- mutate(bulkspeed, Wday = wday(bulkspeed$Datetime), Hour = hour(bulkspeed$Datetime))
bulkspeed$Start <- NULL
bulkspeed$Hour <- as.factor(bulkspeed$Hour)
bulkspeed <- tbl_df(bulkspeed)
library(dplyr)
library(ggplot2)
library(lubridate)
parseduration <- function(rawduration) {
rawduration <- strsplit(rawduration, split = ":")
totalseconds <- ( (as.numeric(rawduration[[1]][1]) * 3600)
+ (as.numeric(rawduration[[1]][2]) * 60)
+ (as.numeric(rawduration[[1]][3])) )
return(totalseconds)
}
bulkspeed <- read.delim("./data/bulkspeed201412.txt", stringsAsFactors=FALSE)
bulkspeed <- bulkspeed[ -c(2,4,6,8,10,12,14,16,18,20,22,24) ]
Durationsecs <- sapply(bulkspeed$Duration, function(x) parseduration(x))
df <- as.data.frame(Durationsecs)
bulkspeed <- cbind(bulkspeed, df)
bulkspeed <- mutate(bulkspeed, Secs.Bib = round(Durationsecs / Records, 2))
bulkspeed <- mutate(bulkspeed, Datetime = mdy_hm(bulkspeed$Start))
bulkspeed <- mutate(bulkspeed, Wday = wday(bulkspeed$Datetime), Hour = hour(bulkspeed$Datetime))
bulkspeed$Start <- NULL
bulkspeed$Hour <- as.factor(bulkspeed$Hour)
bulkspeed <- tbl_df(bulkspeed)
write.csv(bulkspeed, file="./output/mutatedbulkspeed-201412.csv")
419 + 2471 + 16 + 2611
5517 / 7555
419 + 2471 + 16 + 2611
args(rm)
args(ls)
args(rbind)
scanraw <-scan("data/rawlinks.txt",sep="\t", header=FALSE, stringsAsFactors = FALSE)
scanraw <-scan("data/rawlinks.txt",sep="\t", stringsAsFactors = FALSE)
scanraw <-scan("data/rawlinks.txt",sep="\t")
`s2.bhl.kbart` <- read.delim("~/datax/R projects/bhl/data/s2-bhl-kbart.tsv")
View(`s2.bhl.kbart`)
bhl <- read.table("data/s2-bhl-kbart.tsv", skip = 58905, nrows = 10)
ch1_ex4 <- read.table("~/datax/R projects/rakov_book/ch1_ex4.txt", header=TRUE, quote="\"")
View(ch1_ex4)
summary(ch1_ex4)
vignette("XLConnect")
help("XLConnect")
help(XLConnect)
loadWorkbook ( filename , create = TRUE )
library(XLConnect)
help(XLConnect)
loadWorkbook ( filename , create = TRUE )
source('~/.active-rstudio-document', echo=TRUE)
install.packages("multicon")
install.packages(c("devtools","roxygen2", "testthat", "knitr"))
install.packages("rstudioapi")
rstudioapi::isAvailable("0.99.149")
library(devtools)
has_devel()
library(roxygen2)
library(testthat)
devtools::session_info()
options()
480 * 186000
1.05 / (sqrt(7))
(1.05 / (sqrt(7)) ) * 2.447
devtools::session_info()
2*2*2*2*2
2^5
library(flexdashboard)
library(tidyverse)
library(plotly)
library(readr)
# import data
countit_lts <- read_csv("~/datax/R projects/count-it_LTStrends/input/countit_lts.csv",
col_types = cols(date = col_date(format = "%m/%d/%Y"),
datetime = col_datetime(format = "%m/%d/%Y %H:%M"),
day = col_factor(levels = c("Mon",
"Tue", "Wed", "Thu", "Fri"))))
briefdf <- countit_lts %>% select(datetime, day, totaltime, topic, notes)
View(countit_lts)
View(briefdf)
# Analysis of Notes
#text analysis
library(tidytext)
library(dplyr)
library(stringr)
library(DT)
text_df <- data_frame(line = 1:nrow(countit_lts), text = countit_lts$notes)
text_df$text <- str_replace_all(text_df$text, "#", "h_")
ttdf <- text_df %>%
unnest_tokens(word, text)
df_tt_notes_wordcounts <- ttdf %>%
filter(!word %in% stop_words$word) %>%
count(word, sort= TRUE)
tt_hash_only <- df_tt_notes_wordcounts %>% filter(grepl("h_",word))
tt_hash_only$word <- str_replace_all(tt_hash_only$word, "h_", "")
tt_hash_only %>%
arrange(desc(n)) %>%
DT::datatable()
View(tt_hash_only)
p <- ggplot(tt_hash_only, aes(word, n) ) + geom_point()  + ggtitle("Hash word by total time")
ggplotly(p)
View(df_tt_notes_wordcounts)
View(text_df)
View(tt_hash_only)
View(df_tt_notes_wordcounts)
View(briefdf)
View(text_df)
View(text_df)
View(countit_lts)
View(briefdf)
View(countit_lts)
p <- ggplot(weekcount, aes(week, count) ) + geom_bar(stat="identity")  + ggtitle("# of E-resource Count-it Events by Week of Year") + annotate("text", x = 35, y = 15, label = "Aug 29 - Sep 2")
weekcount <- countit_lts %>% group_by(week) %>% summarise(count = n() )
p <- ggplot(weekcount, aes(week, count) ) + geom_bar(stat="identity")  + ggtitle("# of E-resource Count-it Events by Week of Year") + annotate("text", x = 35, y = 15, label = "Aug 29 - Sep 2")
ggplotly(p)
p <- ggplot(weekcount, aes(week, count) ) + geom_bar(stat="identity")  + ggtitle("# of E-resource Count-it Events by Week of Year") + annotate("text", x = 35, y = 15, label = "Aug 29 - Sep 2", color="red")
ggplotly(p)
View(countit_lts)
View(briefdf)
daycount <- countit_lts %>% group_by(day) %>% summarise(count = n() )
p <- ggplot(daycount, aes(day, count) ) + geom_bar(stat="identity") + ggtitle("# of E-resource Count-it Events by Day of Week") + geom_point()
ggplotly(p)
weekcount <- countit_lts %>% group_by(week) %>% summarise(count = n() )
p <- ggplot(weekcount, aes(week, count) ) + geom_bar(stat="identity")  + ggtitle("# of E-resource Count-it Events by Week of Year") + annotate("text", x = 35, y = 15, label = "Aug 29 - Sep 2", color="red") + geom_point()
ggplotly(p)
weekcount <- countit_lts %>% group_by(week) %>% summarise(count = n() )
p <- ggplot(weekcount, aes(week, count) )   + ggtitle("# of E-resource Count-it Events by Week of Year") + annotate("text", x = 35, y = 15, label = "Aug 29 - Sep 2", color="red") + geom_point()
ggplotly(p)
p <- ggplot(weekcount, aes(week, count) )   + ggtitle("# of E-resource Count-it Events by Week of Year") + annotate("text", x = 35, y = 15, label = "Aug 29 - Sep 2", color="red") + geom_line()
ggplotly(p)
p <- ggplot(weekcount, aes(week, count) ) + geom_bar(stat="identity")  + ggtitle("# of E-resource Count-it Events by Week of Year") + annotate("text", x = 35, y = 15, label = "Aug 29 - Sep 2", color="red")
ggplotly(p)
View(df_tt_notes_wordcounts)
View(ttdf)
library(tidytext)
View(text_df)
View(df_tt_notes_wordcounts)
View(text_df)
unrest_tokens
2+6+6+7+7+6+5+3+3+4+8+2
knitr::opts_chunk$set(echo = TRUE)
grp1 <- c(1,2,3,4)
grp2 <- c(5,6,7,8)
grp3 <- c(9,10,11,12)
total_SS <- sum((c(grp1, grp2, grp3) - mean(c(grp1, grp2, grp3)))\^2)
total_SS
total_SS <- sum((c(grp1, grp2, grp3) - mean(c(grp1, grp2, grp3)))\^2)
total_SS <- sum((c(grp1, grp2, grp3) - mean(c(grp1, grp2, grp3)))^2)
total_SS
within_SS <- sum((c(grp1 - mean(grp1), grp2 - mean(grp2), grp3 - mean(grp3)))^2)
within_SS
between_SS <- 4*(sum((c(mean(grp1), mean(grp2), mean(grp3))^2 - mean(df$y)^2)))
between_SS <- 4(sum((c(mean(grp1), mean(grp2), mean(grp3))^2 - mean(df$y)^2)))
between_SS <- 4 * sum((c(mean(grp1), mean(grp2), mean(grp3))^2 - mean(df$y)^2))
between_SS <- sum((c(mean(grp1), mean(grp2), mean(grp3))^2)
between_SS
between_SS <- sum((c(mean(grp1), mean(grp2), mean(grp3))^2))
between_SS
between_SS <- sum((c(mean(grp1), mean(grp2), mean(grp3))^2)) - mean(df$y)^2)
between_SS <- sum((c(mean(grp1), mean(grp2), mean(grp3))^2)) - mean(df$y)^2
mean(df$y)^2
sum(1193,208,93,32,95)
sum(208,93,32,95)
428/1621
require(installr)
updateR()
version
devtools::install_github("rstats-db/odbc")
library("odbc", lib.loc="~/R/R-3.4.1/library")
devtools::install_github("rstats-db/odbc")
devtools::install_github("rstats-db/odbc", force=TRUE)
con <- DBI::dbConnect(odbc::odbc(),
Driver = "Voyager",
Host   = "jdbc:oracle:thin:@reports7.library.cornell.edu:1521:VGER",
SVC    = "CORNELLDB",
UID    = rstudioapi::askForPassword("dbread"),
PWD    = rstudioapi::askForPassword("dbread"),
Port   = 1521)
library(DBI)
con <- dbConnect(odbc::odbc(), "Voyager")
setwd("~/datax/R projects/linked_data_survey")
library(readr)
ld_results_rob_adam <- read_csv("ld_results_rob_adam.csv")
View(ld_results_rob_adam)
cor(ld_results_rob_adam$benefits_quality, ld_results_rob_adam$adam_optimism)
cor(ld_results_rob_adam$benefits_quality, ld_results_rob_adam$adam_optimism, use="complete.obs")
cor(ld_results_rob_adam$benefits_score, ld_results_rob_adam$adam_optimism, use="complete.obs")
library(readr)
ld_results_rob_adam <- read_csv("ld_results_rob_adam.csv")
View(ld_results_rob_adam)
cor(ld_results_rob_adam$benefits_score, ld_results_rob_adam$adam_optimism, use="complete.obs")
cor(ld_results_rob_adam$benefits_quality, ld_results_rob_adam$adam_contains_ideas, use="complete.obs")
library(readr)
ld_results_rob_adam <- read_csv("ld_results_rob_adam.csv")
View(ld_results_rob_adam)
cor(ld_results_rob_adam$benefits_quality, ld_results_rob_adam$adam_benefits_quality, use="complete.obs")
cor(ld_results_rob_adam$benefits_score, ld_results_rob_adam$adam_benefits_score, use="complete.obs")
library(readxl)
ld_results_rob_adam <- read_excel("ld_results_rob_adam.xlsx")
View(ld_results_rob_adam)
cor(ld_results_rob_adam$benefits_score, ld_results_rob_adam$adam_benefits_score, use="complete.obs")
cor(ld_results_rob_adam$benefits_quality, ld_results_rob_adam$adam_benefits_quality, use="complete.obs")
library(tidyverse)
library(readxl)
ld_results_rob_adam <- read_excel("ld_results_rob_adam.xlsx")
df <- ld_results_rob_adam %>%
mutate(benefits_score + adam_benefits_score)
View(df)
df <- ld_results_rob_adam %>%
mutate(benefits_total = benefits_score + adam_benefits_score)
View(df)
View(df)
View(df)
library(tidyverse)
library(readxl)
library(tidytext)
library(wordcloud)
setwd("~/datax/R projects/linked_data_survey")
ld_results_rob_adam <- read_excel("ld_results_rob_adam.xlsx")
df <- ld_results_rob_adam %>%
mutate(benefits_total = benefits_score + adam_benefits_score)
# word cloud
df %>% count(word) %>% with(wordcloud(word, n, max.words = 60))
text_df <- df %>%
unnest_tokens(word, linked_data_benefits)
# word cloud
text_df %>% count(word) %>% with(wordcloud(word, n, max.words = 60))
data(stop_words)
text_df <- df %>%
unnest_tokens(word, linked_data_benefits) %>%
anti_join(stop_words)
# word cloud
text_df %>% count(word) %>% with(wordcloud(word, n, max.words = 60))
png(filename="plots/wordcloud.png")
dev.copy(jpeg,filename="plots/wordcloud.png");
dev.off ();
dev.copy(jpeg,filename="plots/wordcloud.jpg");
dev.off ();
dev.copy(jpeg,filename="plots/benefits_wordcloud.jpg");
dev.off ();
text_df_high_benefits <- df %>%
filter(benefits_total == 2) %>%
unnest_tokens(word, linked_data_benefits) %>%
anti_join(stop_words)
# word cloud
text_df_high_benefits %>% count(word) %>% with(wordcloud(word, n, max.words = 60))
dev.copy(jpeg,filename="plots/high_benefits_wordcloud.jpg");
dev.off ();
benefits_words <- df() %>%
unnest_tokens(word, linked_data_benefits) %>%
count(book, word, sort = TRUE) %>%
ungroup()
benefits_words <- df %>%
unnest_tokens(word, linked_data_benefits) %>%
count(book, word, sort = TRUE) %>%
ungroup()
benefits_words <- df %>%
unnest_tokens(word, linked_data_benefits) %>%
count(response_id, word, sort = TRUE) %>%
ungroup()
View(benefits_words)
total_words <- benefits_words %>%
group_by(response_id) %>%
summarize(total = sum(n))
View(total_words)
benefits_words <- left_join(benefits_words, total_words)
View(benefits_words)
library(ggplot2)
ggplot(benefits_words, aes(n/total, fill = response_id)) +
geom_histogram(show.legend = FALSE) +
xlim(NA, 0.0009) +
facet_wrap(~response_id, ncol = 2, scales = "free_y")
freq_by_rank <- benefits_words %>%
group_by(response_id) %>%
mutate(rank = row_number(),
`term frequency` = n/total)
freq_by_rank
View(freq_by_rank)
benefits_words <- df %>%
filter(benefits_total == 2) %>%
unnest_tokens(word, linked_data_benefits) %>%
count(response_id, word, sort = TRUE) %>%
ungroup()
total_words <- benefits_words %>%
group_by(response_id) %>%
summarize(total = sum(n))
benefits_words <- left_join(benefits_words, total_words)
freq_by_rank <- benefits_words %>%
group_by(response_id) %>%
mutate(rank = row_number(),
`term frequency` = n/total)
freq_by_rank
View(freq_by_rank)
