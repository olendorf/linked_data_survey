source('~/r_projects/linked_data_survey/survey_analysis.R')
source('~/r_projects/linked_data_survey/survey_analysis.R')
get_sentiments("nrc")
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("nrc"))
tokenized_survey$sentiment <- NULL
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("nrc"))
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("afinn"))
source('~/r_projects/linked_data_survey/survey_analysis.R')
get_sentiments('loughran')
###################
## Automate package install and load
is_installed <- function(package_name) is.element(package_name, installed.packages()[,1])
# If a package is not installed, install it. Then load the package.
install_and_load <- function(package_name) {
if(!is_installed(package_name)) {
install.packages(package_name)
}
library(package_name, character.only = TRUE)
}
install_packages <- function(packages) {
for(package in packages) {
install_and_load(package)
}
}
# Install and load libraries
install_packages(c("dplyr", "tidytext", "readr", "ggplot2", "stringr"))
survey = read_csv('ld_results_final__for_rob_recoded_trimmed.csv', col_names = TRUE)
survey$combined_words <- paste(survey$linked_data_description, survey$linked_data_benefits, survey$additional_thoughts)
tokenized_survey <- survey %>% unnest_tokens(word, combined_words)
data("stop_words")
tokenized_survey <- tokenized_survey %>% anti_join(stop_words)
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("bing"))
tokenized_survey$bing_sentiment <- tokenized_survey$sentiment
tokenized_survey$sentiment <- NULL
tokenized_survey <- tokenized_survey %>% inner_join(get_sentiments("nrc"))
tokenized_survey$nrc_sentiment <- tokenized_survey$sentiment
source('~/r_projects/linked_data_survey/survey_analysis.R')
View(tokenized_survey_nrc)
View(tokenized_survey_nrc)
View(tokenized_survey_nrc)
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
bing_word_counts %>%
group_by(bing_sentiment) %>%
top_n(7) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n, fill = bing_sentiment)) +
geom_col(show.legend = FALSE) +
facet_wrap(~bing_sentiment, scales = "free_y") +
labs(y = "Contribution to sentiment",
x = NULL) +
coord_flip()
View(tokenized_survey)
View(tokenized_survey)
View(tokenized_survey_nrc)
View(tokenized_survey_nrc)
View(tokenized_survey)
View(tokenized_survey)
View(survey)
View(survey)
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
library("topicmodels", lib.loc="~/Library/R/3.3/library")
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
install_url(slam_url)
R.version()
R.Version()
R.Version()
install.packages('devtools')
slam_url <- "https://cran.r-project.org/src/contrib/Archive/slam/slam_0.1-37.tar.gz"
install_url(slam_url)
slam_url <- "https://cran.r-project.org/src/contrib/Archive/slam/slam_0.1-37.tar.gz"
install_url(slam_url)
library(devtools)
install_url(slam_url)
install_url(slam_url)
install.packages("git2r")
install.packages("slam")
libary('slam')
library("slam", lib.loc="~/Library/R/3.4/library")
init_data <- data("AssociatedPress")
install.packages("topicmodels")
library("topicmodels", lib.loc="~/Library/R/3.4/library")
init_data <- data("AssociatedPress")
init_data
ap_lda <- LDA(init_data, k = 2, control = list(seed = 1234))
data("AssociatedPress")
<<DocumentTermMatrix
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234))
ap_lda
install_packages(c("devtools", "dplyr", "tidytext", "readr", "ggplot2", "stringr", "topicmodels"))
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
word_counts_dtm <- word_counts %>% cast_dtm(response_id, word, n)
word_counts <- tokenized_survey %>%
group_by(response_id) %>%
count(word, sort = TRUE) %>%
left_join(tokenized_survey %>%
group_by(response_id) %>%
summarise(total = n()))
##################
## Automate package install and load
is_installed <- function(package_name) is.element(package_name, installed.packages()[,1])
# If a package is not installed, install it. Then load the package.
install_and_load <- function(package_name) {
if(!is_installed(package_name)) {
install.packages(package_name)
}
library(package_name, character.only = TRUE)
}
install_packages <- function(packages) {
for(package in packages) {
install_and_load(package)
}
}
# Install and load libraries
install_packages(c("topicmodels", "dplyr", "tidytext", "readr", "ggplot2", "stringr", "dataMeta"))
# Load the data
survey = read_csv('ld_results_final__for_rob_recoded_trimmed.csv', col_names = TRUE)
# Mush all th etext columns together to increase power
survey$combined_words <- paste(survey$linked_data_description, survey$linked_data_benefits, survey$additional_thoughts)
# Tokenize the words
tokenized_survey <- survey %>% unnest_tokens(word, combined_words)
# Remove stop words and join
data("stop_words")
tokenized_survey <- tokenized_survey %>% anti_join(stop_words)
word_counts <- tokenized_survey %>%
group_by(response_id) %>%
count(word, sort = TRUE) %>%
left_join(tokenized_survey %>%
group_by(response_id) %>%
summarise(total = n()))
word_counts_dtm <- word_counts %>% cast_dtm(response_id, word, n)
responses_lda <- LDA(word_counts_dtm, k = 4, control = list(seed = 1234))
survey_topics <- tidy(responses_lda, matrix = "beta")
top_terms <- survey_topics %>% group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
word_counts_dtm <- word_counts %>% cast_dtm(response_id, word, n)
responses_lda <- LDA(word_counts_dtm, k = 2, control = list(seed = 1234))
survey_topics <- tidy(responses_lda, matrix = "beta")
top_terms <- survey_topics %>% group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
stop_words
tail(stop_words)
c(stop_words, ["data", "custom"])
c(stop_words, c("data", "custom"))
stop_words
add_row(stop_words, word = "library", lexicon = "custom", .before = 0)
data("stop_words")
stop_words
new_stops = c("data", "linked", "information", "library")
add_row(stop_words, word = new_stops, lexicon = "custom", .before = 0)
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
View(stop_words)
View(stop_words)
responses_lda <- LDA(word_counts_dtm, k = 4, control = list(seed = 1234))
survey_topics <- tidy(responses_lda, matrix = "beta")
top_terms <- survey_topics %>% group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
data("stop_words")
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
View(stop_words)
View(stop_words)
source('~/Documents/r_projects/linked_data_survey/survey_analysis.R')
word_counts <- tokenized_survey %>%
group_by(response_id) %>%
count(word, sort = TRUE) %>%
left_join(tokenized_survey %>%
group_by(response_id) %>%
summarise(total = n()))
word_counts_dtm <- word_counts %>% cast_dtm(response_id, word, n)
responses_lda <- LDA(word_counts_dtm, k = 4, control = list(seed = 1234))
survey_topics <- tidy(responses_lda, matrix = "beta")
top_terms <- survey_topics %>% group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
tokenized_survey <- survey %>% unnest_tokens(word, combined_words)
View(tokenized_survey)
View(tokenized_survey)
